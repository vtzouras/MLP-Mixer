model:
  name: "MLP_Mixer"
  image_size: 32
  patch_size: 4
  num_channels: 3
  embed_dim: 128
  num_classes: 10
  depth: 8
  token_dim: 64
  channel_dim: 512
  dropout: 0.0

training:
  epochs: 100
  batch_size: 128
  learning_rate: 0.001
  weight_decay: 0.00005
  optimizer: "adam"
  smooth_labels: 0.1
  scheduler: "WarmupCosineLR"
  warmup_epochs: 5
  warmup_lr_start: 0.000001
  seed: 42

data:
  train_dir: "./data/train"
  test_dir: "./data/test"
  checkpoint_dir: "checkpoints"
  augment: true

augmentation:
  randaugment: True
  randaugment_num_ops: 1
  randaugment_magnitude: 9
  random_erasing: False
  random_erasing_prob: 0.2
  random_erasing_scale: [0.02, 0.33]
  random_erasing_ratio: [0.3, 3.3]
  random_erasing_value: 0
  cutmix: True
  cutmix_prob: 0.2
  mixup: False
  mixup_prob: 0.1
  mix_alpha: 1.0

logging:
  wandb:
    project: "MLP_Mixer-CIFAR"
    entity: "vtzouras"
